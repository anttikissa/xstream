
# TODO (because this still is mostly for myself)

- Stream.sample() that calls a function on every tick, but it's a
  generator so you can just say Stream.sample(Math.random).interval(100)
  to have it update every 100 ms
- .interval(ms) for every generator
- rename (mostly) internal methods like ensureNoCyclicalDependencies
  to start with underscore
- think about end()
- update() logic is documented in multiple places, which is the
  best one?
- reenable test "`leave(n)` is `n` (+ X -- find out why!) ticks behind
  its parent stream." and figure out how many ticks it SHOULD be behind.
- think of what should happen for generators when .end() is called?
  Maybe .updater (or possibly .ended?) should be replaced?
- consider the possibility of calling .end() at the _last_ iteration of 
  generators, so that the .onEnd() handler will be called on the next tick.
  This could be cleaner (in some sense)
- need to keep with the same terminology so it seems that I know what
  I'm doing
- It might be a good idea to make generators that follow another stream.
  Its updater() would only be called whenever another stream is updated.  Like
  a normal link() dependency, but doesn't really depend on the parent
- Make ./test just run the latest failing test, './test all' run all tests, and './test xxx' run tests matching xxx. No silliness like minTest, maxTest.
- REALLY make the tests WORK, now a test can print TOO MUCH and while nothing is expected, everything seems to be fine
- get rid of starvation with process.nextTick() (do setTimeout() on every 1000th iteration, or something?)
- make infinite ranges work in the sense that you can do stream.fromRange(0).take(5) and not have it loop forever
- implement .concat() and .slice() and other array methods. .concat() needs buffering.
- just implement the .mergeLatest and friends. See what happens.
- add .removeListener
- .combineWhenAll (only start to combine once all streams have defined values)
- pick a silly name ('xstream'?) var stream = require('xstream');
- a.rewire(b) should also rewire a.ends() to b.ends() (?)
- Sprinkle assert()s everywhere (strip them out in minimized build)
- Separate tests properly! Make them run serialized. Or at least make
  them totally independent (so that they don't share the same instance of
  `stream`, which makes the transaction queue shared as well)
- and make it possible to use stream.log() in tests.
- .onEnd() is not properly tested with derived streams
- implement .ends() mapping for all primitives, find out if there's
  common functionality to them and abstract away
- ticks vs transactions?
- could we map .ends() lazily? We don't really need to map all of the .ends() and
  .errors() if nobody listens to them?  It would work so that the
  .ends of the resulting stream should be set into a function that
  actually does the thing.
- should stream.link() do the mapping of .ends() and .errors() automatically?
  but merge() should link ends differently than combine().
  merge(): if all streams end, then end.
  combine(): if any of streams end, then end.
  or should combine() also end only when the last one ends?
- should .range(0, Infinity) and other infinite streams stop updating
  themselves if nobody has listened to them for a while? "if a stream
  updates itself in a forest and nobody is listening, does it need to
  update at all?"
  (nobody listening === this.children.length == 0 and this.listeners
  only contains my own listener)
- test stuff like s.update(x); s.end(); within the same tick
- AND s.update(x); s.end(); s.update(y); within the same tick
- nightly implementation idea: s.end() should change .updater to function() {
    throw new Error('stream ended');
  }
- BUT it .end must be a transaction op then, so implement that first.
- crazy idea (or maybe, in hindsight, not so crazy): .rewire(), instead
  of adding a new node and making `this` depend on it, it could just go to
  `.children`() and replace itself with the stream that was given to it
  -- this way there would be no intermediate node and graphs could be
  kept tidy.  BUT of course, all variable references to the old stream
  would still be intact.  So that would be something like
  .rewireDangerousShortcut().
- onEnd() to work correctly (??? figure out the right semantics) for
  reduce() with an initial value and no derived values
  (does it?)
- reduce() could set .value to initialValue and just not broadcast it,
  now would that be silly?
- do some renames: talk about children and parents
  instead of 'dependencies' (maybe?), talk about linking and unlinking
  instead of depends()/rewire (maybe? rewire could do just unlink from
  current parents + link to new ones)
- should prevent .update() from being called when the stream has parents
  (this messes with the topological sort, sets parensCount[id] to -1,
  should've seen that coming)
- mergeStream(stream), mergeStreamLatest(stream)
  (or just call them flatMap(/Latest)?)
- onEnd() to work correctly for other combinators, too (map works)
- Examples (see end)
- Figure out if dependencies need to see which parents were changed.  They
  can check .newValue, of course, but it's a bit dirty. (Implement
  .sampledBy and the answer will be revealed.)
- .end(), .ends()
- .modify(f) (maybe?)
- .errors() and .catch() (OR: do we need error handling at all?)
- Figure out how exceptions should work, which errors they should catch
  and what's the difference between stream error and transaction error
- Separate detailed tests out from README
- Should f have `this` set to resulting node in case of map, combine, etc?
- make something similar to promises .then() (maybe)

.limit(min, max)
//	[stream 1 2 3 4 5].limit(2, 4) -> [stream 2 3 4]
//	[stream { x: 1, y: 5 } { x: 2, y: 5 } { x: 3, y: 6 } ]
//		.limit({ x: 0, y: 6 }, { x: 2, y: 10 }) ->
//		[stream { x: 2, y: 5 } { x: 3, y: 6 }]

## streams.js

Streams, flows, sources, sinks, nodes, whatever.  Figure out a good name.

A few notes to the reader:

*The reader should note that this README experienced explosive growth
with very little gardening.  Things might be introduced in an illogical
order, some things may seem irrelevant or unnecessary, and some things
that should be mentioned might have been omitted. If you find the
situation like that, could you be so kind as to inform me.*

This README is a living test suite, which explains the fact that the
examples may feel a bit too verbose and detailed for general
consumption. (But it's not an excuse - TODO move more detailed tests &
internal tests to another file.)

## Questions a reader might have in mind

TODO answer these eventually

- What's the killer app? (TODO write some cool examples.)

- Why is this library so special? 1) it's easy and simple and small and
  practical 2) thoroughly documented and reasonably easy to understand,
  there are no dependencies (You get hipster points for not using
  jQuery.)

- Is this thing reliable? (Battle-hardened in real projects? No. 100%
  test coverage? No. Dependency handling? Not yet.)

- Is it fast? (I have 10000 streams and with interdependencies, how
  fast is tick()? No idea whatsoever.)

- What's the memory footprint (Can I create 100000 streams with
  callbacks without crashing? How about a million? Hold on. We'll come
  to that.)

- Are there memory leaks? (Can I create 1000 streams per second in a
  long-running application and experience to not run out of memory? No
  idea.)

- Can I read and understand the source code? Is it well commented?
  (Trying my best.)

- Is it debuggable? (Will stack traces be informative? Nope. Not yet
  at least. Eventually, might be able to do at least as much as
  promises. Can I easily see the streams and their states in a
  debugger? Probably, didn't check though. Do streams have identities?
  Yes.) TODO write a section "how to debug stream programs"

- Will the API change? (Likely; we're in 0.0.1 right now.)

- Can I do anything I want with it (you can do many things but the API
  is certainly incomplete. See below.)

- I'd like to do X and Y, how can I implement it easily and submit a
  patch?

- How does this relate to FRP theory and behaviors and signals and event
  streams and push/pull? (No idea as of yet, I'll figure that part out
  later.)


## Background

Draws inspiration from 

- [menrva](https://github.com/phadej/menrva) (auto-committing transactions, taking the idea even further),
- [Bacon.js](https://github.com/baconjs/bacon.js/) (lots of good ideas, trying to simplify it even more), and 
- [The introduction to Reactive Programming you've been missing](https://gist.github.com/staltz/868e7e9bc2a7b8c1f754) (the idea of calling these things 'streams')

## Introduction


The data structure of streams is a... stream.

What's a stream?  Basically,

1. A stream has a value
2. A stream can notify you whenever its value is updated

From these two properties we can derive a multitude of interesting applications.

Let's take a look at the API:

	// Or, if you're in the browser,
	// <script src='xstream.js'></script>
	var stream = require('../xstream');
	console.log(stream) // -> [object Function]

So the main API endpoint is a function. The simplest way to invoke it is
to call it with no arguments, which creates a stream.  

	var s = stream();
	
A stream's value is 'undefined' by default.

	var s = stream();
	console.log(s.value); // -> undefined

You can change the value using `.update()`, but it won't be set immediately.
TODO talk about ticks instead

	var s = stream();
	s.update(1);
	console.log(s.value);
	// -> undefined

	later(function() {
		console.log(s.value);
		// -> 1
	});

As an aside (TODO put this to margin eventually) `later` is defined as:

	function later(f) {
		setTimeout(f, 1);
	}

Internally, streams use `setImmediate` or a similar mechanism to
schedule the transaction.

TODO make this current. In node, it uses `process.nextTick()`. In the
browser, it uses a suitable mechanism (if starvation is a problem,
invent some suitable workaround)

You can call .tick() if you want to set a stream to its value
immediately. A .tick() will update all streams that have an `update` pending:

	var s = stream();
	var s2 = stream();

	s.update(123);
	s2.update(234);
	s.tick();
	console.log(s.value); // -> 123
	// tick() also commits changes to other streams
	console.log(s2.value); // -> 234

`s.tick()` is just a shorthand for `stream.tick()` which is a shorthand for
`stream.transaction().commit()`.  It's not particularly elegant (because
`s.tick()`, in addition to updating `s`, also updates all other streams
that have changes pending), but it's just there because I kept writing
`s.tick()` instead of `stream.tick()` and it was easier to implement a
shorthand than to unlearn a bad habit.  If you want to be pedantic, feel
free to use `stream.tick()` instead.

Also, with `s.tick()`, you can initialize values more easily: `s =
stream(x).tick();`)

Back to `update`. Like many other methods of `stream`, it returns the
stream itself:

	var s = stream();
	console.log(s.update(123) === s);
	// -> true
	
So you can write:

	var s = stream().update(123).tick();
	console.log(s.value);
	// -> 123

Or simply use the constructor `stream(value)`, which triggers
`update(value)` (if `value` is defined):

	var s = stream(123).tick();
	console.log(s.value);
	// -> 123

You can listen for changes in a stream's value:

	var s = stream();
	s.forEach(function(value) {
		console.log(value);
	});

	s.update(1);
	// later:
	// -> 1
	console.log(s.value); // -> 1

Like `.update()`, `.forEach()` returns the set itself, so you can use them in the
same expression:

	var s = stream().forEach(function(value) {
		console.log('s', value); 
	}).update(1);
	// later:
	// -> s 1

The order of `.update()` and `.forEach()` doesn't matter, because the
transaction only happens later:

	var s = stream().update(2).forEach(function(value) {
		console.log('s', value); 
	});
	// later:
	// -> s 2

How do transactions work?

There's `stream.tx`, which is the current transaction if it exists.

Alternatively, you can call stream.transaction() to get the current
transaction, or start a new one if there isn't one already.

	//console.log(stream.tx); // x-> []
	//var s = stream().update(1);
	//console.log(stream.tx); // x-> [[xxx, 1]]

For demonstration purposes, we'll be using a function that just logs its
arguments, so let's give it a name:

	// because if you simply pass console.log around, it'll 
	// have the wrong `this`
	var log = console.log.bind(console);

A stream broadcasts its value always when a new value is set, even if
it's the same as the old value:

	var s = stream();
	s.forEach(log);
	s.update(1);
	setTimeout(function() {
		// -> 1
		s.update(1);
		setTimeout(function() {
			// -> 1
		}, 10);
	}, 10);

However you can get a stream that only broadcasts its value when it
changes with `stream.uniq()` (similar to Unix tool `uniq(1)`)

	var s = stream();
	s.uniq().forEach(log);
	s.update(1);
	setTimeout(function() {
		// -> 1
		s.update(1);
		setTimeout(function() {
			// no effect
		}, 10);
	}, 10);

You can map streams into other streams.

	var s = stream();
	s.forEach(log);
	var s2 = s.map(function(x) { return x * 2; });
	s2.forEach(function(value) {
		console.log('s2 is', value);
	});

	s.update(5);
	// later:
	// -> 5; s2 is 10

	s.update(10);
	// later:
	// -> 10; s2 is 20

Transitive dependencies work:

	var s = stream();
	var s2 = s.map(function(x) { return x + 1; });
	var s3 = s2.map(function(x) { return x * 2; });

	s3.forEach(log);
	s.update(1);
	// later:
	// -> 4

You can convert an array into a stream:

	var numbers = stream.fromArray([1,2,3,4,5]);
	numbers.forEach(log);
	// numbers.onEnd(function(value) { console.log('end'); });
	// later:
	// -> 1; 2; 3; 4; 5

Or make a stream of numbers:

	var numbers = stream.fromRange(1, 10);
	numbers.forEach(log);
	// later:
	// -> 1; 2; 3; 4; 5; 6; 7; 8; 9; 10

It's often useful to just take a few elements of a stream, by using `take(n)`:

	var s = stream.fromRange(1, 10);
	var s2 = s.take(5).forEach(log);
	// later:
	// -> 1; 2; 3; 4; 5

Or take all except the first `n` elements with `skip(n)`:

	var s = stream.fromRange(1, 10);
	var s2 = s.skip(5).forEach(log);
	// later:
	// -> 6; 7; 8; 9; 10

`slice(start, end)` is similar to the array's `slice`:

	var s = stream.fromRange(0, 10);
	var s2 = s.slice(3, 7).forEach(log);
	// later: 
	// -> 3; 4; 5; 6

To follow the `n` last values of a stream, use `slidingWindow(n)`:

	var s = stream.fromRange(1, 5);
	var s2 = s.slidingWindow(3).forEach(log);
	// later:
	// -> [ 1 ]; [ 1, 2 ]; [ 1, 2, 3 ]; [ 2, 3, 4 ]; [ 3, 4, 5 ]

`leave(n)` gives the `n` last values of a stream in an array; alas, it
cannot know when to start tracking its parent stream, because it doesn't
know when it's going to end.  Therefore it needs to keep track of the
previous `n` values (using `slidingWindow`) and turn into a generator
stream after its parent stream has ended.

	var s = stream.fromRange(1, 10);
	var s2 = s.leave(5).forEach(log);
	// later:
	// -> 6; 7; 8; 9; 10

You can give a step to be used with the range:

	var numbers = stream.fromRange(0, 50, 10);
	numbers.forEach(log);
	// later:
	// -> 0; 10; 20; 30; 40; 50

Infinite ranges are ok, although it's a good idea to stop it eventually
with `end()`.

	var numbers = stream.fromRange(0);
	numbers.forEach(function(value) {
		console.log(value);
		if (value == 5) {
			this.end();
		}
	});
	// later:
	// -> 0; 1; 2; 3; 4; 5

To create an infinite range with a step, just use `Infinity` as the end value:

	var oddNumbers = stream.fromRange(1, Infinity, 2);
	oddNumbers.forEach(function(value) {
		console.log(value);
		if (value == 5) {
			this.end();
		}
	});
	// later:
	// -> 1; 3; 5

You can `end()` an array stream, too:

	var numbers = stream.fromArray([1,2,3,4,5,6,7,8,9,10]);
	numbers.forEach(function(value) {
		console.log(value);
		if (value == 5) {
			this.end();
		}
	});
	// later:
	// -> 1; 2; 3; 4; 5

// TODO eventually add .pause(), .play(), .rewind(), .interval(),
// maybe .delay() to these kinds of streams, give them a name
// 'timed stream', 'buffered stream', 'automatic stream', 'generator stream',
// or something

You should be able to set how long a delay `fromArray()` (or an
`update()`) is.

//	stream.fromValues(1,2,3).delay(100);
	// wait 100 ms, then give 1, 2, 3 in a burst

//	stream.fromValues(1).delay(100);
	// should be equivalent to
//	stream().update(1).delay(100);
	// but .update() already committed a transaction!
	// this means that we should have means to remove a stream from
	// the transaction queue. transaction().remove(stream) ->
	// would return an array of operations.

This may need some magic (for instance, an internal .rewire())

Streams can be filtered, like arrays:

	var numbers = stream.fromArray([1,2,3,4,5,6,7,8,9,10]);
	var oddNumbers = numbers.filter(function(value) {
		return value % 2;
	});
	//	numbers.forEach(function(value) { console.log('nums', value); });
	oddNumbers.forEach(log);
	// later:
	// -> 1; 3; 5; 7; 9

You can combine streams to make new streams.  Whenever one of the source
streams is updated, the resulting stream is updated as well.

	var s1 = stream(1);
	var s2 = stream(1);
	var s3 = stream.combine(s1, s2, function(value1, value2) {
		return value1 * value2;
	});
	s3.forEach(log);
	s1.update(2);
	// later:
	// -> 2
	s2.update(3);
	// later:
	// -> 6

Works with three streams, as well. This example introduces two more ways
to create a stream, `fromValues` and `fromString`:

TODO is it just an implementation artifact that s1 and s2 are updated in
the same commit? Debug this!

	var s1 = stream.fromValues(1,2,3,4,5);
	var s2 = stream.fromString('abcde');
	var s3 = s2.map(function(s) { return s.toUpperCase(); });

	stream.combine(s1, s2, s3, Array).forEach(log);
	// later:
	// -> [ 1, 'a', 'A' ]; [ 2, 'b', 'B' ]; [ 3, 'c', 'C' ]

Combining with `Array` is a common enough operation to warrant its own
name, `zip`:

	var s1 = stream.fromArray([1,2,3]);
	var s2 = stream.fromString('abc');
	stream.zip(s1, s2).forEach(log);
	// later:
	// -> [ 1, 'a' ]; [ 2, 'b' ]; [ 3, 'c' ]

TODO is there any sense in this?

Normally, streams only notify their listeners whenever their value
changes.  But sometimes you don't care about the value, just about the
notification.  In those cases you can trigger the notification manually:

	var s = stream();
	s.forEach(function() { console.log('ping'); });
	s.forEach(function() { console.log('pong'); });
	s.broadcast();
	// -> ping; pong

You can merge two streams:

	var s = stream();
	var s2 = stream();
	var both = stream.merge(s, s2).forEach(log);

	s.update(1).tick();
	// -> 1
	s2.update(2).tick();
	// -> 2

	s.update(3);
	s2.update(4);
	stream.tick();
	// Note that if both streams are updated within the same
	// transaction, only the later value will be taken into
	// account in the merged stream:
	// -> 4

And reduce them, like you would an array:

	var s = stream.fromValues(1,2,3,4,5);
	s.reduce(function(a, b) {
		return a + b;
	}).forEach(log);
	// later:
	// -> 1; 3; 6; 10; 15

A common case of using `reduce` is collecting all values into an array.
`reduce` gets an optional initial value.  Note that `reduce` only
produces values whenever the original stream is updated, and therefore
will not broadcast its initial value unless the original streams ends
without updating itself once.

	var s = stream.fromValues(1,2,3);
	var all = s.reduce(function(array, value) {
		return array.concat([value]);
	}, []);
	all.forEach(log);
	//	s.collect().forEach(log);
	// later:
	// -> [ 1 ]; [ 1, 2 ]; [ 1, 2, 3 ]

The dependency handler functions should only be called after all
children have been updated. The following example sets up a network of 9
streams (3 sources and 6 dependent streams) and ensures that each
dependency handler is called only once.

	var s1 = stream(1);
	var s2 = stream(2);
	var s3 = stream(3);

	var plusCount = 0;
	var plus = function(a, b, c) { plusCount++; return a + b + c; }
	var mulCount = 0;
	var mul = function(a, b, c) { mulCount++; return a * b * c; }

	var s4 = stream.combine(s1, s2, s3, plus);
	var s5 = stream.combine(s1, s2, s3, plus);
	var s6 = stream.combine(s1, s2, s3, plus);

	var s7 = stream.combine(s4, s5, s6, mul);
	var s8 = stream.combine(s4, s5, s6, mul);
	var s9 = stream.combine(s4, s5, s6, mul).forEach(log);

	// later:
	// (1 + 2 + 3) * (1 + 2 + 3) * (1 + 2 + 3)
	// -> 216
	// A naive implementation would call plus 9 times
	console.log(plusCount); // -> 3
	// A naive implementation would call mul 27 times
	console.log(mulCount); // -> 3

TODO move more detailed tests to their own file

Sometimes it's useful to 'rewire' streams. `s.rewire(newSource)` makes
`s` follow the value of `newSource`, without breaking any streams or
listeners that depend on `s` itself.

	var s1 = stream(1);
	s1.map(function(x) { return x + 1; }).forEach(log);
	// later:
	// -> 2
	s1.rewire(stream.combine(
		stream(5),
		stream.fromValues(1, 2, 3), function(a, b) {
			return a * b;
		}));
	// later:
	// -> 6; 11; 16
	
`rewire` discards the stream's old dependencies and copies its
dependencies from the given stream:

	var oldSource = stream(1);
	var s = oldSource.map(function(x) { return x + 1; }).forEach(log);
	// later:
	// -> 2
	var newSource = stream(2);
	s.rewire(newSource);
	stream.tick();
	// -> 2
	oldSource.update(5).tick();
	stream.tick();
	// no effect

`rewire` also rewires the .ends() streams:

	var s1 = stream();
	var s2 = stream();
	s1.onEnd(function(value) { console.log('end 1:', value); });
	s2.onEnd(function(value) { console.log('end 2:', value); });
	s2.rewire(s1.map(stream.util.inc));
	s1.update(123);
	s1.end();
	stream.tick();
	// -> end 1: 123; end 2: 124

Streams can end, which means that they no longer want to broadcast
values. You can listen to end events by using the stream `s.ends()`,
which is a stream that gets updated with the last value of the stream
immediately when it ends:

	var s = stream.fromValues(1,2,3).forEach(log);
	s.ends().forEach(function(lastValue) {
		console.log('ended with', lastValue);
	});
	// later:
	// -> 1; 2; 3; ended with 3

If a stream ends within the same transaction as its value is set, the
end value will be same as the value set during the transaction:

	var s = stream();
	s.ends().forEach(log);
	s.update(1); // the order doesn't matter; or should it?
	s.end();
	s.tick();
	// -> 1

How about:

	var s = stream();
	s.ends().forEach(log);
	s.update(1);
	s.end();
	s.update(2);
	s.tick();
	// should probably get something like 'cannot .update() and ended
	// stream'

Mapped streams end when the parent stream ends:

	var s = stream();
	var s2 = s.map(function(x) { return x * 2; });
	s.onEnd(function(value) { console.log('s ended with', value); });
	s2.onEnd(function(value) { console.log('s2 ended with', value); });
	s.update(123);
	s.end();
	// later:
	// -> s ended with 123; s2 ended with 246

Reduced streams end when the parent stream

.merge() is actually flatMap() when generalized to streams
.concat() similarly could also take a stream of arrays (but if one
.end()s, the whole stream end()s and it stops listening)
.reduce()
.errors(),
.ends()

.ends() returns the last value of the stream, to enable things
like:

	stream.fromArray([1,2,3,4]).reduce(function(a, b) {
		return a + b;
	}).ends().forEach(function(sum) {
		console.log('sum is', sum);
		// -> sum is 10
	});

Could .ends() return multiple times?

Would a stream be able to fork() somehow?

;					   ---> x4' ---> x5' ---> x6' ---> x7' ---> end
;					  /
;	x1 ---> x2 ---> x3 ---> x4 ----> x5 ----> x6 ----> end
;							 \
;							  -----> x5'' --> end

`ends().forEach()` would give you x5'', x6, and x7', and then `ends()`
itself would end.  But you'd have to define the semantics for what
`fork()` means.  Maybe this needs the concept of 'producer functions' --
some streams (for example, stream.sample(Math.random(), 100) generalize
nicely in this way.

It could be a nice way to explore alternative futures, but it really
shouldn't complicate the normal implementation in any way.

TODO this was originally about .forEach() returning duplicates, which is
the way it now works; rewrite this:

When can that be useful? For instance, if you are making a game and want
a random number on every frame:

	return "test disabled";
	var randomStream = stream.sample(function() {
		// Produce a random digit
		return Math.random().toString().charAt(2);
	}, 1000 / 60);

	log('random')
	// -> prints a number 60 times per second

`sample`, by the way, either takes a stream or a function, and takes its
value at a specified interval.

`sample` can be used to to synchronize streams to another stream that is
used as a clock stream, to make other streams update simultaneously:

	return "test disabled";
	var clock = stream.clock(1000 / 60);
	var mouseMoves = stream.fromEvent(document, 'mousemove').pluck(['x', 'y']);
	var randoms = stream.sample(Math.random, clock);
	var coords = stream.sample(mouseMoveStream, clock);

	stream.combine(randoms, coords, function(random, coord) {
		// do something with them
	});

You can use `stream.frame` to return a stream that is synchronized with
an `requestAnimationFrame` callback:

	return "test disabled";
	var s = stream.frame(); // or frames() or .animationFrames() or something
	// Do stream.frame.forEach() or something to do some drawing
	// TODO How to avoid the .setImmediate caused by .forEach()?
	// .map(...).assign(domElement, 'property')?

You may have noticed that .map() and .forEach() are quite like the array
functions of the same name.  Streams are like arrays in other respects,
too.

But before that, let's introduce a third property of streams:

3. A stream can notify you when it no longer wants to broadcast its value

You can end a stream by calling `stream.end()`, and listen to end events by
calling `stream.onEnd()`.  It's equivalent to `stream.ends().forEach()`,
except that in the callback, `this` is set to the stream instead of the
end stream.

	var s = stream();
	s.forEach(log);
	s.onEnd(function() { console.log('end'); });
	s.update(2);
	s.tick(); // -> 2
	s.end();
	s.tick(); // -> end
	// you can still access its final value directly
	console.log(s.value); // -> 2
	// but it won't broadcast its value to listeners
	// in fact, it's an error to update() an ended stream:
	s.update(3); 
	try {
		s.tick();
	} catch (e) {
		console.log(e.message); // -> cannot update ended stream
	}

Or you can convert an array into a stream that broadcasts a new value
every X milliseconds, using setInterval() internally:

	var numbers2 = stream.fromArray([1,2,3,4,5], 100);
	numbers2.forEach(function(value) { console.log(value); });
	// (during the next 500 ms) -> 1; 2; 3; 4; 5

Ranges work, too:

	var someNumbers = stream.fromRange(1, 5).forEach(log);
	stream.tick(5);
	// -> 1; 2; 3; 4; 5
	var allIntegers = stream.fromRange(0).forEach(log);
	stream.tick(4);
	allIntegers.end(); // prevent stream from ticking indefinitely
	// -> 0; 1; 2; 3

	// The third argument is the step
	var someEvenNumbers = stream.fromRange(0, 10, 2).forEach(log);
	stream.tick(6);
	// -> 0; 2; 4; 6; 8; 10
	// If you need to use step with infinite ranges, you can use Infinity
	var allEvenNumbers = stream.fromRange(0, Infinity, 2).forEach(log); 
	stream.tick(6);
	// -> 0; 2; 4; 6; 8; 10
	allEvenNumbers.end();

Several other array utilities work, too:

`concat` combines several streams sequentially. Naturally, for this to
work as expected, all of the concatenated streams must be finite, except
for the last one.

	return "test disabled";
	first = stream.fromArray([1,2,3]);
	second = stream.fromArray([4,5]);
	first.concat(second).forEach(function(value) {
		console.log(value);
	}); // -> 1; 2; 3; 4; 5

`concat` is actually the reason why I first needed .onEnd() and .end(),
but I figure they might be useful in other contexts, too.

You can `filter` a stream; the resulting stream only broadcasts the
value if a predicate returns true.

	var numbers = stream.fromRange(1);
	var oddNumbers = numbers.filter(function(value) {
		return (value % 2);
	}).forEach(log);

	stream.tick(5);
	// -> 1; 3; 5
	numbers.end();

`find` returns a stream whose value is undefined until a value is found
in the stream, after which it ends immediately. If the original stream
ends before a value is found, it ends without never yielding a value.

	return "test disabled";
	var numbers = stream.fromRange(0);
	var foundStream = stream.find(function(value) { return value == 42; });
	foundStream.forEach(log); // -> 42

findIndex
indexOf
join
pop, push?
shift, unshift?
reduce, reduceRight?

slice(start, end)
take(n) is shorthand for slice(0, n)
leave(n) is shorthand for slice(0, -n) (use sliding window .end())
skip(n) is shorthand for slice(n)
step(n) take every n'th value

Other commonly used helpers:

also stream.zip(s1, s2, s3)

zipWith() is actually the same as combine() 

.every() is true before an element is found that makes it false?
.some() is false before an element is found that makes it true?

Should s1.zip(s2) be a shorthand for stream.zip(s1, s2)
and same for combine() and possibly others?


## Transactions

Stream updates are atomic: outside observers will never see inconsistent
state.  This is achieved using transactions.

Whenever you make a modification on a stream using `.update()`, it starts a
transaction or continues a new one.

A transaction is simply a set of modifications that will be performed on nodes:

	return "test disabled";
	//var s = stream(1);
	//var s2 = s.map(double);
	//log(stream.tx); // -> []
	//s.update(2);
	//log(s.value); // -> undefined
	//log(s2.value); // -> undefined

	//s.forEach(log);
	//s2.forEach(log);

	//log(stream.tx); // -> [stream(undefined), 1]

	// You can commit a transaction manually:
	//stream.tick(); // -> 2; 4
	//log(stream.tx); // -> []
	//log(s.value); // -> 2
	//log(s2.value); // -> 4

You can also use transactions to modify a stream atomically. Consider
the classical bank account transfer example:

	return "test disabled";
	var bobAccount = stream(100); // Bob has $100
	var maryAccount = stream(200); // Mary has $200

	function sendMoney(from, to, amount) {
		function deposit(balance, amount) {
			return balance + amount;
		}

		function withdraw(balance, amount) {
			if (amount > balance) {
				throw new InsufficientFundsException('need more');
			}
			return balance - value;
		}

		to.modify(function(balance) {
			return deposit(balance, amount);
		});
	
		from.modify(function(balance) {
			return withdraw(balance, amount);
		});

		// Similar to bluebird's .catch() handlers
		stream.transaction()
			.catch(InsufficientFundsException, function(e) {
				console.log(e.message);
			}).commit();
	}

	sendMoney(bobAccount, maryAccount, 101);
	// -> need more
	console.log(bobAccount.value, maryAccount.value);
	// unchanged:
	// -> 100 200
	sendMoney(maryAccount, bobAccount, 50);
	console.log(bobAccount.value, maryAccount.value);
	// -> 150 150

## Re-wiring a stream

Conceptually, a stream consists of two parts: its identity, which
consists of its value and its listeners, and its implementation, which
dictates where its value comes from.

When you create a stream and give it a name, possibly using it somewhere
else, you give it a permanent, unchangeable identity. At the same time,
it gets an implementation.

	var someStream = stream(123);
	var mapped = someStream.map(function(value) { return value * 2; });
	var combined = stream.combine(someStream, mapped, function(a, b) {
		return a + b;
	});

You can now change someStream's underlying implementation by saying, for
example:

	//someStream.rewire(stream.combine(s1, s2, f(v1, v2) { ... }));

This changes causes changes in `s1` and `s2` to be propagated to
`someStream`, and eventually to `mapped` and `combined`.

TODO circular dependencies, detecting them

## DOM events

You can map DOM events into streams.

	return "test disabled";
	var clicks = stream.fromEvent('.close1', 'click');

## Examples

TODO 
- Snake (like in http://philipnilsson.github.io/badness/)
  - Especially interesting in terms of how .slidingWindowBy() would be
    implemented in streams
- Could implement Tetris as well since I never did that
- Excel in 100 lines (like http://anttisykari.kapsi.fi/menrva-cells/ but with .rewire() and interface code implemented with streams)
- ...
- Simple parsing (filtering out '/* */' and '//' C comments from a stream)
- Implementing a useful primitive (like the abovementioned parser)
- Every method in the API should have a useful real-world example
  (otherwise it doesn't belong to the library)
- Create a 'make' style build tool
- Convert mktest into using streams
- Classic autocomplete example
- http://elm-lang.org/ has the time traveling thing
- form with username & two password fields
  - check that passwords match
  - that username/email is not taken
  - etc.
  - maybe validate email too
- Example: MMO, stream that monitors network latency and fades the
  screen when it is too big
- Physics simulator

